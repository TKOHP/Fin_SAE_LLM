{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T00:49:48.220303200Z",
     "start_time": "2024-07-23T00:49:38.905501800Z"
    }
   },
   "outputs": [],
   "source": [
    "from sae_lens import CacheActivationsRunnerConfig,CacheActivationsRunner\n",
    "cfg=CacheActivationsRunnerConfig(\n",
    "    model_name=\"pythia-14m\",\n",
    "    hook_name=\"blocks.0.hook_mlp_out\",\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",\n",
    "    context_size=512,\n",
    "    d_in=128,\n",
    "    training_tokens=1024*30_00,\n",
    "    n_shuffles_final=100,\n",
    "    shuffle_every_n_buffers= 100,\n",
    "    n_shuffles_with_last_section= 100,\n",
    "    n_shuffles_in_entire_dir= 100,\n",
    "    n_batches_in_buffer=8,\n",
    "    store_batch_size_prompts=8,\n",
    "    new_cached_activations_path=\"D:/project/dataset/activations/1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T00:51:08.162416Z",
     "start_time": "2024-07-23T00:49:50.533624100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-14m into HookedTransformer\n",
      "Started caching 3072000 activations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching activations: 100%|██████████| 94/94 [01:33<00:00,  1.01it/s]\n",
      "Final shuffling:   0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "SafetensorError",
     "evalue": "Error while serializing: IoError(Os { code: 1224, kind: Uncategorized, message: \"请求的操作无法在使用用户映射区域打开的文件上执行。\" })",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mSafetensorError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m a\u001B[38;5;241m=\u001B[39m\u001B[43mCacheActivationsRunner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\tools\\anaconda3\\envs\\llm_test\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\tools\\anaconda3\\envs\\llm_test\\lib\\site-packages\\sae_lens\\cache_activations_runner.py:120\u001B[0m, in \u001B[0;36mCacheActivationsRunner.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_buffers \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    119\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mn_shuffles_final), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinal shuffling\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 120\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshuffle_activations_pairwise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnew_cached_activations_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbuffer_idx_range\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_buffers\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\tools\\anaconda3\\envs\\llm_test\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\tools\\anaconda3\\envs\\llm_test\\lib\\site-packages\\sae_lens\\cache_activations_runner.py:161\u001B[0m, in \u001B[0;36mCacheActivationsRunner.shuffle_activations_pairwise\u001B[1;34m(self, datapath, buffer_idx_range)\u001B[0m\n\u001B[0;32m    158\u001B[0m shuffled_buffer2 \u001B[38;5;241m=\u001B[39m joint_buffer[buffer1\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] :]\n\u001B[0;32m    160\u001B[0m \u001B[38;5;66;03m# Save them back\u001B[39;00m\n\u001B[1;32m--> 161\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactivations_store\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_buffer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    162\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffled_buffer1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mdatapath\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mbuffer_idx1\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfile_extension\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[0;32m    163\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivations_store\u001B[38;5;241m.\u001B[39msave_buffer(\n\u001B[0;32m    165\u001B[0m     shuffled_buffer2, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdatapath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbuffer_idx2\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_extension\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    166\u001B[0m )\n",
      "File \u001B[1;32mD:\\tools\\anaconda3\\envs\\llm_test\\lib\\site-packages\\sae_lens\\training\\activations_store.py:564\u001B[0m, in \u001B[0;36mActivationsStore.save_buffer\u001B[1;34m(self, buffer, path)\u001B[0m\n\u001B[0;32m    559\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msave_buffer\u001B[39m(\u001B[38;5;28mself\u001B[39m, buffer: torch\u001B[38;5;241m.\u001B[39mTensor, path: \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    560\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    561\u001B[0m \u001B[38;5;124;03m    Used by cached activations runner to save a buffer to disk.\u001B[39;00m\n\u001B[0;32m    562\u001B[0m \u001B[38;5;124;03m    For reuse by later workflows.\u001B[39;00m\n\u001B[0;32m    563\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 564\u001B[0m     \u001B[43msave_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mactivations\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\tools\\anaconda3\\envs\\llm_test\\lib\\site-packages\\safetensors\\torch.py:284\u001B[0m, in \u001B[0;36msave_file\u001B[1;34m(tensors, filename, metadata)\u001B[0m\n\u001B[0;32m    253\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msave_file\u001B[39m(\n\u001B[0;32m    254\u001B[0m     tensors: Dict[\u001B[38;5;28mstr\u001B[39m, torch\u001B[38;5;241m.\u001B[39mTensor],\n\u001B[0;32m    255\u001B[0m     filename: Union[\u001B[38;5;28mstr\u001B[39m, os\u001B[38;5;241m.\u001B[39mPathLike],\n\u001B[0;32m    256\u001B[0m     metadata: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    257\u001B[0m ):\n\u001B[0;32m    258\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    259\u001B[0m \u001B[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001B[39;00m\n\u001B[0;32m    260\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    282\u001B[0m \u001B[38;5;124;03m    ```\u001B[39;00m\n\u001B[0;32m    283\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 284\u001B[0m     \u001B[43mserialize_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_flatten\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mSafetensorError\u001B[0m: Error while serializing: IoError(Os { code: 1224, kind: Uncategorized, message: \"请求的操作无法在使用用户映射区域打开的文件上执行。\" })"
     ]
    }
   ],
   "source": [
    "a=CacheActivationsRunner(cfg).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T01:03:09.704409800Z",
     "start_time": "2024-07-23T00:58:42.830074500Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-14m into HookedTransformer\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m a\u001B[38;5;241m=\u001B[39mCacheActivationsRunner(cfg)\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;43mprint\u001B[39;49m(a)\n",
      "Cell \u001B[1;32mIn[7], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m a\u001B[38;5;241m=\u001B[39mCacheActivationsRunner(cfg)\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;43mprint\u001B[39;49m(a)\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\tools\\PyCharm 2023.2.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\tools\\PyCharm 2023.2.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "a=CacheActivationsRunner(cfg)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oAsZCAdJOVHw",
    "outputId": "9b75fff2-3f7e-410b-c0f6-d473f5e56c7d",
    "ExecuteTime": {
     "end_time": "2024-07-23T02:29:23.869487600Z",
     "start_time": "2024-07-23T02:27:48.539015200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tools\\anaconda3\\envs\\llm_test\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Run name: 1024-L1-5-LR-5e-05-Tokens-3.072e+06\n",
      "n_tokens_per_buffer (millions): 0.032768\n",
      "Lower bound: n_contexts_per_buffer (millions): 6.4e-05\n",
      "Total training steps: 3000\n",
      "Total wandb updates: 100\n",
      "n_tokens_per_feature_sampling_window (millions): 524.288\n",
      "n_tokens_per_dead_feature_window (millions): 524.288\n",
      "We will reset the sparsity calculation 3 times.\n",
      "Number tokens in sparsity calculation window: 1.02e+06\n",
      "使用存储的activations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: 1134952622 (1134952622-beijing-u). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6707adbe3acc4d74856ef82ef81d40fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.17.4"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>D:\\project\\LLM\\myproject\\wandb\\run-20240723_102826-aymo46ga</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/1134952622-beijing-u/sae_lens_tutorial/runs/aymo46ga' target=\"_blank\">1024-L1-5-LR-5e-05-Tokens-3.072e+06</a></strong> to <a href='https://wandb.ai/1134952622-beijing-u/sae_lens_tutorial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/1134952622-beijing-u/sae_lens_tutorial' target=\"_blank\">https://wandb.ai/1134952622-beijing-u/sae_lens_tutorial</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/1134952622-beijing-u/sae_lens_tutorial/runs/aymo46ga' target=\"_blank\">https://wandb.ai/1134952622-beijing-u/sae_lens_tutorial/runs/aymo46ga</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000| MSE Loss 0.836 | L1 0.000: 100%|██████████| 3072000/3072000 [00:37<00:00, 82216.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='1.008 MB of 1.008 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a21402381b0443e3b270e372aabf9109"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▅██████████████████████████████████████</td></tr><tr><td>details/current_learning_rate</td><td>████████████████████████████████▇▇▆▅▄▃▂▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/ghost_grad_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/mse_loss</td><td>▆█▇▆▆▆▄▆▄▂▅▄▃▃▃▄▄▄▄▃▃▃▅▁▃▂▁▁▂▂▂▃▂▂▂▂▂▂▂▄</td></tr><tr><td>losses/overall_loss</td><td>██▇▅▆▆▄▆▄▂▅▄▃▃▃▄▄▄▄▃▃▃▅▁▃▂▁▁▂▂▂▃▂▂▂▂▂▂▂▄</td></tr><tr><td>metrics/explained_variance</td><td>▁▁▃▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇████████████</td></tr><tr><td>metrics/explained_variance_std</td><td>██▆▇▇▆▆▅▅▅▄▅▅▅▅▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂</td></tr><tr><td>metrics/l0</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▁▁</td></tr><tr><td>sparsity/below_1e-5</td><td>▁██</td></tr><tr><td>sparsity/below_1e-6</td><td>▁██</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▇▇█████████████████████</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>5</td></tr><tr><td>details/current_learning_rate</td><td>0.0</td></tr><tr><td>details/n_training_tokens</td><td>3072000</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>0.0</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.0</td></tr><tr><td>losses/l1_loss</td><td>0.0</td></tr><tr><td>losses/mse_loss</td><td>0.8356</td></tr><tr><td>losses/overall_loss</td><td>0.8356</td></tr><tr><td>metrics/explained_variance</td><td>0.00185</td></tr><tr><td>metrics/explained_variance_std</td><td>0.02817</td></tr><tr><td>metrics/l0</td><td>0.0</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-10.0</td></tr><tr><td>sparsity/below_1e-5</td><td>1024</td></tr><tr><td>sparsity/below_1e-6</td><td>1024</td></tr><tr><td>sparsity/dead_features</td><td>1024</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>2746.30664</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">1024-L1-5-LR-5e-05-Tokens-3.072e+06</strong> at: <a href='https://wandb.ai/1134952622-beijing-u/sae_lens_tutorial/runs/aymo46ga' target=\"_blank\">https://wandb.ai/1134952622-beijing-u/sae_lens_tutorial/runs/aymo46ga</a><br/> View project at: <a href='https://wandb.ai/1134952622-beijing-u/sae_lens_tutorial' target=\"_blank\">https://wandb.ai/1134952622-beijing-u/sae_lens_tutorial</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20240723_102826-aymo46ga\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gpu_mem_track import MemTracker\n",
    "import torch\n",
    "import os\n",
    "import torch.autograd.profiler as profiler\n",
    "from sae_lens import LanguageModelSAERunnerConfig, SAETrainingRunner\n",
    "device = \"cuda\"\n",
    "print(\"Using device:\", device)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "gpu_tracker = MemTracker()\n",
    "total_training_steps = 30_00  # probably we should do more\n",
    "batch_size = 1024\n",
    "total_training_tokens = total_training_steps * batch_size\n",
    "\n",
    "lr_warm_up_steps = 0\n",
    "lr_decay_steps = total_training_steps // 5  # 20% of training\n",
    "l1_warm_up_steps = total_training_steps // 20  # 5% of training\n",
    "\n",
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"pythia-14m\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_name=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_layer=0,  # Only one layer in the model.\n",
    "    d_in=128,  # the width of the mlp output.\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
    "    # dataset_path=\"roneneldan/TinyStories\",\n",
    "    is_dataset_tokenized=True,\n",
    "    streaming=False,  # we could pre-download the token dataset if it was small.\n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=2**3,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n",
    "    normalize_sae_decoder=False,\n",
    "    scale_sparsity_penalty_by_decoder_norm=True,\n",
    "    decoder_heuristic_init=True,\n",
    "    init_encoder_as_decoder_transpose=True,\n",
    "    # normalize_activations=\"expected_average_only_in\",\n",
    "    normalize_activations=\"none\",\n",
    "    # Training Parameters\n",
    "    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n",
    "    adam_beta2=0.999,\n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n",
    "    l1_coefficient=5,  # will control how sparse the feature activations are\n",
    "    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size_tokens=batch_size,\n",
    "    context_size=512,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=8,  # controls how many activations we store / shuffle.\n",
    "    # n_batches_in_buffer=8,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    # store_batch_size_prompts=32,\n",
    "    store_batch_size_prompts=8,\n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False,  # we don't use ghost grads anymore.\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    # WANDB\n",
    "    log_to_wandb=True,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"sae_lens_tutorial\",\n",
    "    wandb_log_frequency=30,\n",
    "    eval_every_n_wandb_logs=20,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    # act_store_device=\"cpu\",\n",
    "    seed=42,\n",
    "    n_checkpoints=0,\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=\"float32\",\n",
    "    # store_activations\n",
    "    use_cached_activations=True,\n",
    "    cached_activations_path=\"D:/project/dataset/activations/1\"\n",
    "\n",
    ")\n",
    "# look at the next cell to see some instruction for what to do while this is running.\n",
    "sparse_autoencoder = SAETrainingRunner(cfg).run(gpu_tracker,track=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/jbloomAus/SAELens/blob/main/tutorials/training_a_sparse_autoencoder.ipynb",
     "timestamp": 1721283432729
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
